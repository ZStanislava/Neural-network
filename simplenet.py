# -*- coding: utf-8 -*-
"""SimpleNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RFnuv5hv8wMusysDdfFDVRS2HnyxvtjW

# **Работа с данными**
"""

#монтирование GDrive
from google.colab import drive
drive.mount('/content/drive')

#разархивирование animals.zip, находящегося на GDrive
!unzip "/content/drive/My Drive/animals.zip"

"""# **Создание и обучение простой нейронной сети**"""

# импортируем бэкенд Agg из matplotlib для сохранения графиков на диск
import matplotlib
matplotlib.use("Agg")

# подключаем необходимые пакеты
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from keras.models import Sequential
from keras.layers.core import Dense
from keras.optimizers import SGD
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import random
import pickle
import cv2
import os

dataset = "/content/animals"
model_ = "/content/output/simple_nn.model"
label_bin = "/content/output/simple_nn_lb.pickle"
plot = "/content/output/simple_nn_plot.png"

# инициализируем данные и метки
data = []
labels = []

# берём пути к изображениям и рандомно перемешиваем
imagePaths = sorted(list(paths.list_images(dataset)))
random.seed(42)
random.shuffle(imagePaths)

# цикл по изображениям
for imagePath in imagePaths:
	# загружаем изображение, меняем размер на 32x32 пикселей (без учета
	# соотношения сторон), сглаживаем его в 32x32x3=3072 пикселей и
	# добавляем в список
	image = cv2.imread(imagePath)
	image = cv2.resize(image, (32, 32)).flatten()
	data.append(image)

	# извлекаем метку класса из пути к изображению и обновляем
	# список меток
	label = imagePath.split(os.path.sep)[-2]
	labels.append(label)

# масштабируем интенсивности пикселей в диапазон [0, 1]
data = np.array(data, dtype="float") / 255.0
labels = np.array(labels)

# разбиваем данные на обучающую и тестовую выборки, используя 75%
# данных для обучения и оставшиеся 25% для тестирования
(trainX, testX, trainY, testY) = train_test_split(data,
	labels, test_size=0.25, random_state=42)

# конвертируем метки из целых чисел в векторы (для 2х классов при
# бинарной классификации вам следует использовать функцию Keras
# “to_categorical” вместо “LabelBinarizer” из scikit-learn, которая
# не возвращает вектор)
lb = LabelBinarizer()
trainY = lb.fit_transform(trainY)
testY = lb.transform(testY)

# определим архитектуру 3072-1024-512-3 с помощью Keras
model = Sequential()
model.add(Dense(1024, input_shape=(3072,), activation="sigmoid"))
model.add(Dense(512, activation="sigmoid"))
model.add(Dense(len(lb.classes_), activation="softmax"))

# инициализируем скорость обучения и общее число эпох
INIT_LR = 0.01
EPOCHS = 75

# компилируем модель, используя SGD как оптимизатор и категориальную
# кросс-энтропию в качестве функции потерь (для бинарной классификации
# следует использовать binary_crossentropy)
opt = SGD(lr=INIT_LR)
model.compile(loss="categorical_crossentropy", optimizer=opt,
	metrics=["accuracy"])

# обучаем нейросеть
H = model.fit(trainX, trainY, validation_data=(testX, testY),
	epochs=EPOCHS, batch_size=32)

# оцениваем нейросеть
predictions = model.predict(testX, batch_size=32)
print(classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1), target_names=lb.classes_))

mkdir "/content/output"

# строим графики потерь и точности
N = np.arange(0, EPOCHS)
plt.style.use("ggplot")
plt.figure()
plt.plot(N, H.history["loss"], label="train_loss")
plt.plot(N, H.history["val_loss"], label="val_loss")
plt.plot(N, H.history["acc"], label="train_acc")
plt.plot(N, H.history["val_acc"], label="val_acc")
plt.title("Training Loss and Accuracy (Simple NN)")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()
plt.savefig(plot)

from google.colab.patches import cv2_imshow
img = cv2.imread("/content/output/simple_nn_plot.png")
cv2_imshow(img)

# сохраняем модель и бинаризатор меток на диск
model.save(model_)
f = open(label_bin, "wb")
f.write(pickle.dumps(lb))
f.close()

"""# **Распознавание с помощью обученной модели**"""

from keras.models import load_model
import pickle
import cv2

#разархивирование images.zip, находящегося на GDrive
!unzip "/content/drive/My Drive/images.zip"

image_ = "/content/images/panda.jpg"
model_ = "/content/output/simple_nn.model"
label_bin = "/content/output/simple_nn_lb.pickle"
width = 32
height = 32
flatten = 1

# загружаем входное изображение и меняем его размер на необходимый
image = cv2.imread(image_)
output = image.copy()
image = cv2.resize(image, (width, height))

# масштабируем значения пикселей к диапазону [0, 1]
image = image.astype("float") / 255.0

# проверяем, необходимо ли сгладить изображение и добавить размер
# пакета
if flatten > 0:
	image = image.flatten()
	image = image.reshape((1, image.shape[0]))
# в противном случае мы работаем с CNN -- не сглаживаем изображение
# и просто добавляем размер пакета
else:
	image = image.reshape((1, image.shape[0], image.shape[1],
		image.shape[2]))

# загружаем модель и бинаризатор меток
model = load_model(model_)
lb = pickle.loads(open(label_bin, "rb").read())

# делаем предсказание на изображении
preds = model.predict(image)
print(preds)

# находим индекс метки класса с наибольшей вероятностью
# соответствия
i = preds.argmax(axis=1)[0]
label = lb.classes_[i]

# рисуем метку класса + вероятность на выходном изображении
text = "{}: {:.2f}%".format(label, preds[0][i] * 100)
cv2.putText(output, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
	(0, 0, 255), 2)

# показываем выходное изображение
from google.colab.patches import cv2_imshow
cv2_imshow(output)

"""# **Создание и обучение свёрточной нейронной сети**

**Создание**
"""

# импортируем необходимые пакеты
from keras.models import Sequential
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dropout
from keras.layers.core import Dense
from keras import backend as K

class SmallVGGNet:
	@staticmethod
	def build(width, height, depth, classes):
		# инициализируем модель и размер входного изображения
		# для порядка каналов “channel_last” и размер канала
		model = Sequential()
		inputShape = (height, width, depth)
		chanDim = -1

		# если мы используем порядок "channels first", обновляем
		# входное изображение и размер канала
		if K.image_data_format() == "channels_first":
			inputShape = (depth, height, width)
			chanDim = 1

		# слои CONV => RELU => POOL
		model.add(Conv2D(32, (3, 3), padding="same",
			input_shape=inputShape))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))

		# слои (CONV => RELU) * 2 => POOL
		model.add(Conv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(Conv2D(64, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))

		# (CONV => RELU) * 3 => POOL layer set
		model.add(Conv2D(128, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(Conv2D(128, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(Conv2D(128, (3, 3), padding="same"))
		model.add(Activation("relu"))
		model.add(BatchNormalization(axis=chanDim))
		model.add(MaxPooling2D(pool_size=(2, 2)))
		model.add(Dropout(0.25))

		# первый (и единственный) набор слоев FC => RELU
		model.add(Flatten())
		model.add(Dense(512))
		model.add(Activation("relu"))
		model.add(BatchNormalization())
		model.add(Dropout(0.5))

		# классификатор softmax
		model.add(Dense(classes))
		model.add(Activation("softmax"))

		# возвращаем собранную архитектуру нейронной сети
		return model

"""**Обучение**"""

# импортируем бэкенд Agg из matplotlib для сохранения графиков на диск
import matplotlib
matplotlib.use("Agg")

# подключаем необходимые пакеты
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import SGD
from imutils import paths
import matplotlib.pyplot as plt
import numpy as np
import argparse
import random
import pickle
import cv2
import os

dataset = "/content/animals"
model_ = "/content/output/smallvggnet.model"
label_bin = "/content/output/smallvggnet_lb.pickle"
plot = "/content/output/smallvggnet_plot.png"

# инициализируем данные и метки
data = []
labels = []

# берём пути к изображениям и рандомно перемешиваем
imagePaths = sorted(list(paths.list_images(dataset)))
random.seed(42)
random.shuffle(imagePaths)

# цикл по изображениям
for imagePath in imagePaths:
	# загружаем изображение, меняем размер на 64x64 пикселей
	# (требуемые размеры для SmallVGGNet), изменённое изображение
	# добавляем в список
	image = cv2.imread(imagePath)
	image = cv2.resize(image, (64, 64))
	data.append(image)

	# извлекаем метку класса из пути к изображению и обновляем
	# список меток
	label = imagePath.split(os.path.sep)[-2]
	labels.append(label)

# масштабируем интенсивности пикселей в диапазон [0, 1]
data = np.array(data, dtype="float") / 255.0
labels = np.array(labels)

# разбиваем данные на обучающую и тестовую выборки, используя 75%
# данных для обучения и оставшиеся 25% для тестирования
(trainX, testX, trainY, testY) = train_test_split(data,
	labels, test_size=0.25, random_state=42)

# конвертируем метки из целых чисел в векторы (для 2х классов при
# бинарной классификации вам следует использовать функцию Keras
# “to_categorical” вместо “LabelBinarizer” из scikit-learn, которая
# не возвращает вектор)
lb = LabelBinarizer()
trainY = lb.fit_transform(trainY)
testY = lb.transform(testY)

# создаём генератор для добавления изображений
aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,
	height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
	horizontal_flip=True, fill_mode="nearest")

# инициализируем нашу VGG-подобную сверточную нейросеть
model = SmallVGGNet.build(width=64, height=64, depth=3,
	classes=len(lb.classes_))

# инициализируем скорость обучения, общее число эпох
# и размер пакета
INIT_LR = 0.01
EPOCHS = 75
BS = 32

# компилируем модель с помощью SGD (для бинарной классификации
# следует использовать binary_crossentropy)
print("[INFO] training network...")
opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)
model.compile(loss="categorical_crossentropy", optimizer=opt,
	metrics=["accuracy"])

# обучаем нейросеть
H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),
	validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,
	epochs=EPOCHS)

# оцениваем нейросеть
predictions = model.predict(testX, batch_size=32)
print(classification_report(testY.argmax(axis=1),
	predictions.argmax(axis=1), target_names=lb.classes_))

# строим графики потерь и точности
N = np.arange(0, EPOCHS)
plt.style.use("ggplot")
plt.figure()
plt.plot(N, H.history["loss"], label="train_loss")
plt.plot(N, H.history["val_loss"], label="val_loss")
plt.plot(N, H.history["acc"], label="train_acc")
plt.plot(N, H.history["val_acc"], label="val_acc")
plt.title("Training Loss and Accuracy (SmallVGGNet)")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend()
plt.savefig(plot)

from google.colab.patches import cv2_imshow
img = cv2.imread("/content/output/smallvggnet_plot.png")
cv2_imshow(img)

# сохраняем модель и бинаризатор меток на диск
model.save(model_)
f = open(label_bin, "wb")
f.write(pickle.dumps(lb))
f.close()

"""# **Распознавание с помощью свёрточной сети**"""

from keras.models import load_model
import pickle
import cv2

image_ = "/content/images/dog.jpg"
model_ = "/content/output/smallvggnet.model"
label_bin = "/content/output/smallvggnet_lb.pickle"
width = 64
height = 64
flatten = -1

# загружаем входное изображение и меняем его размер на необходимый
image = cv2.imread(image_)
output = image.copy()
image = cv2.resize(image, (width, height))

# масштабируем значения пикселей к диапазону [0, 1]
image = image.astype("float") / 255.0

# проверяем, необходимо ли сгладить изображение и добавить размер
# пакета
if flatten > 0:
	image = image.flatten()
	image = image.reshape((1, image.shape[0]))
# в противном случае мы работаем с CNN -- не сглаживаем изображение
# и просто добавляем размер пакета
else:
	image = image.reshape((1, image.shape[0], image.shape[1],
		image.shape[2]))

# загружаем модель и бинаризатор меток
model = load_model(model_)
lb = pickle.loads(open(label_bin, "rb").read())

# делаем предсказание на изображении
preds = model.predict(image)
print(preds)

# находим индекс метки класса с наибольшей вероятностью
# соответствия
i = preds.argmax(axis=1)[0]
label = lb.classes_[i]

# рисуем метку класса + вероятность на выходном изображении
text = "{}: {:.2f}%".format(label, preds[0][i] * 100)
cv2.putText(output, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
	(0, 0, 255), 2)

# показываем выходное изображение
from google.colab.patches import cv2_imshow
cv2_imshow(output)